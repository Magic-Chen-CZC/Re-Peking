# ç»Ÿä¸€ Chunking æ¥å£é‡æ„æ€»ç»“

**æ—¥æœŸ**: 2025-12-14  
**ä»»åŠ¡**: å°†æ‰€æœ‰ processors ç»Ÿä¸€ä½¿ç”¨ `domain_config.py` ä¸­çš„ chunking é…ç½®

---

## ğŸ“‹ é‡æ„ç›®æ ‡

1. **ç»Ÿä¸€é…ç½®ç®¡ç†**: æ‰€æœ‰ä¸šåŠ¡ç±»å‹çš„åˆ‡åˆ†å‚æ•°é›†ä¸­åœ¨ `domain_config.py`
2. **æ¶ˆé™¤ç¡¬ç¼–ç **: åˆ é™¤å„ processor ä¸­çš„ç¡¬ç¼–ç åˆ‡åˆ†å‚æ•°
3. **æºå¤´è¿‡æ»¤**: åœ¨åˆ‡åˆ†æ—¶å°±è¿‡æ»¤æ‰è¿‡çŸ­çš„ chunkï¼Œé¿å…æ— æ•ˆ LLM è°ƒç”¨
4. **ä¿æŒæ‰©å±•æ€§**: ä¿ç•™ `mode` å­—æ®µä»¥ä¾¿åç»­æ”¯æŒ markdown/å…¶ä»–åˆ‡åˆ†æ¨¡å¼

---

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

### 1. `modules/domain_config.py`

**ç»Ÿä¸€ chunking é…ç½®ç»“æ„**ï¼š

```python
"chunking": {
    "mode": "sentence",    # åˆ‡åˆ†æ¨¡å¼ï¼ˆä¿ç•™ä»¥ä¾¿æ‰©å±•ï¼‰
    "chunk_size": 800,     # æ¯å—æœ€å¤§å­—ç¬¦æ•°
    "overlap": 100,        # å—ä¹‹é—´é‡å å­—ç¬¦æ•°
    "min_length": 150,     # æœ€å°å—é•¿åº¦ï¼ˆæºå¤´è¿‡æ»¤ï¼‰
}
```

**å„ä¸šåŠ¡ç±»å‹é…ç½®**ï¼š

| ä¸šåŠ¡ç±»å‹ | mode | chunk_size | overlap | min_length | è¯´æ˜ |
|---------|------|------------|---------|------------|------|
| **xhs** | none | 0 | 0 | 50 | ä¸åˆ†å—ï¼ˆçŸ­æ–‡æœ¬ï¼‰ |
| **legend** | sentence | 800 | 100 | 150 | æ•…äº‹æ–‡æ¡£ |
| **arch** | sentence | 600 | 80 | 200 | å»ºç­‘æ–‡æ¡£ï¼ˆä¿¡æ¯å¯†åº¦é«˜ï¼‰ |

**æ–°å¢è¾…åŠ©å‡½æ•°**ï¼š
- `get_chunking_config(domain_type)`: è·å–å®Œæ•´ chunking é…ç½®

---

### 2. `modules/processors/pdf_processor.py`

**âœ… é‡æ„ `_split_text()` æ–¹æ³•**ï¼š

```python
def _split_text(self, text: str, domain_config: Dict[str, Any]) -> List[str]:
    """
    ä½¿ç”¨é…ç½®ä¸­çš„ chunking å‚æ•°åˆ‡åˆ†æ–‡æœ¬ï¼Œå¹¶é¢„è¿‡æ»¤çŸ­æ–‡æœ¬
    
    æºå¤´è¿‡æ»¤é€»è¾‘ï¼š
    - åœ¨åˆ‡åˆ†åç«‹å³æ£€æŸ¥æ¯ä¸ª chunk çš„é•¿åº¦
    - è¿‡æ»¤æ‰ len(chunk) < min_length çš„å—
    - é¿å…å¯¹è¿‡çŸ­æ–‡æœ¬è°ƒç”¨ LLMï¼ˆèŠ‚çœ API è´¹ç”¨ï¼‰
    """
    # è·å– chunking é…ç½®
    chunking = domain_config.get('chunking', {})
    mode = chunking.get('mode', 'sentence')
    chunk_size = chunking.get('chunk_size', 512)
    overlap = chunking.get('overlap', 64)
    min_length = chunking.get('min_length', 0)
    
    # æ ¹æ® mode é€‰æ‹©åˆ‡åˆ†ç­–ç•¥
    if mode == 'none':
        chunks = [text]  # ä¸åˆ‡åˆ†
    else:
        # ä½¿ç”¨ SentenceSplitter æŒ‰å­—æ•°åˆ‡åˆ†
        splitter = SentenceSplitter(
            chunk_size=chunk_size,
            chunk_overlap=overlap,
        )
        nodes = splitter.get_nodes_from_documents([Document(text=text)])
        chunks = [node.text for node in nodes if node.text.strip()]
    
    # ã€æºå¤´è¿‡æ»¤ã€‘è¿‡æ»¤è¿‡çŸ­çš„ chunk
    if min_length > 0:
        original_count = len(chunks)
        chunks = [chunk for chunk in chunks if len(chunk) >= min_length]
        filtered_count = original_count - len(chunks)
        if filtered_count > 0:
            logger.info(f"å·²è¿‡æ»¤ {filtered_count} ä¸ªè¿‡çŸ­çš„ chunk")
    
    return chunks
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… åŠ¨æ€è¯»å– chunking é…ç½®ï¼ˆä¸å†ç¡¬ç¼–ç ï¼‰
- âœ… æ”¯æŒ `mode='none'` ä¸åˆ†å—æ¨¡å¼
- âœ… æºå¤´è¿‡æ»¤ï¼šåˆ‡åˆ†åç«‹å³æ£€æŸ¥é•¿åº¦
- âœ… æ—¥å¿—è®°å½•è¿‡æ»¤ç»Ÿè®¡

---

### 3. `modules/processors/xhs_processor.py`

**âœ… æ›¿æ¢æ—§çš„ `strategies` ä¸º `domain_config`**ï¼š

```python
# ä¿®æ”¹å‰
from modules.strategies import get_strategy
self.strategy = get_strategy("xhs")
system_prompt = self.strategy.prompt

# ä¿®æ”¹å
from modules.domain_config import get_domain_config
self.domain_config = get_domain_config("xhs")
system_prompt = self.domain_config['prompt']
```

**âœ… ç®€åŒ– instructor æ¨¡å¼**ï¼š

```python
# ä¿®æ”¹å‰ï¼šå®šä¹‰ä¸´æ—¶ Extraction æ¨¡å‹
class XHSNoteExtraction(BaseModel):
    location: Optional[str] = ...
    # ...

extraction = client.create(..., response_model=XHSNoteExtraction)

# ä¿®æ”¹åï¼šç›´æ¥ä½¿ç”¨ domain_config çš„ schema
schema_class = self.domain_config['schema']
extraction = client.create(..., response_model=schema_class)
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… ç»Ÿä¸€ä½¿ç”¨ `domain_config`
- âœ… åˆ é™¤é‡å¤çš„ä¸´æ—¶æ¨¡å‹å®šä¹‰
- âœ… ç›´æ¥ä½¿ç”¨é…ç½®ä¸­çš„ Schema

---

### 4. `fetch_data.py` - Web æ•°æ®å¤„ç†

**âœ… é‡æ„ `fetch_web_data()` å‡½æ•°**ï¼š

```python
# ä¿®æ”¹å‰ï¼šç¡¬ç¼–ç åˆ‡åˆ†å‚æ•°
text_splitter = SentenceSplitter(
    chunk_size=512,
    chunk_overlap=64,
    separator="\n"
)
doc = Document(text=full_text)
nodes = text_splitter.get_nodes_from_documents([doc])
chunks = [node.text for node in nodes if node.text.strip()]

# ä¿®æ”¹åï¼šä½¿ç”¨ç»Ÿä¸€çš„å¤„ç†é€»è¾‘
processor = PDFProcessor()
chunks = processor._split_text(full_text, domain_config)
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… åˆ é™¤ç¡¬ç¼–ç åˆ‡åˆ†å‚æ•°
- âœ… å¤ç”¨ PDFProcessor çš„ç»Ÿä¸€åˆ‡åˆ†é€»è¾‘
- âœ… è‡ªåŠ¨åº”ç”¨ chunking é…ç½®å’Œæºå¤´è¿‡æ»¤

---

## ğŸ¯ ç»Ÿä¸€åçš„æ•°æ®å¤„ç†æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  domain_config.py (é…ç½®ä¸­å¿ƒ)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ "xhs": { chunking: {mode: none, min_length: 50}}â”‚   â”‚
â”‚  â”‚ "legend": {chunking: {size: 800, min: 150}}    â”‚   â”‚
â”‚  â”‚ "arch": {chunking: {size: 600, min: 200}}      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚
          â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ pdf_processor.py â”‚  â”‚ xhs_processor.py â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚_split_text() â”‚ â”‚  â”‚ â”‚ä½¿ç”¨ config   â”‚ â”‚
â”‚ â”‚  â†“           â”‚ â”‚  â”‚ â”‚['schema']    â”‚ â”‚
â”‚ â”‚è¯»å– chunking â”‚ â”‚  â”‚ â”‚['prompt']    â”‚ â”‚
â”‚ â”‚é…ç½®          â”‚ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚  â†“           â”‚ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚æŒ‰ mode åˆ‡åˆ†  â”‚ â”‚           â”‚
â”‚ â”‚  â†“           â”‚ â”‚           â”‚
â”‚ â”‚æºå¤´è¿‡æ»¤      â”‚ â”‚           â”‚
â”‚ â”‚min_length    â”‚ â”‚           â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
          â”‚                    â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  ç»Ÿä¸€çš„ LLM å¤„ç†  â”‚
         â”‚  + Pydantic éªŒè¯ â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Excel åŠ¨æ€å¯¼å‡º  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š é‡æ„æ•ˆæœå¯¹æ¯”

| æŒ‡æ ‡ | é‡æ„å‰ | é‡æ„å | æ”¹è¿› |
|------|--------|--------|------|
| **é…ç½®ä½ç½®** | åˆ†æ•£åœ¨ 3 ä¸ªæ–‡ä»¶ | é›†ä¸­åœ¨ `domain_config.py` | âœ… ç»Ÿä¸€ç®¡ç† |
| **ç¡¬ç¼–ç å‚æ•°** | å¤šå¤„ç¡¬ç¼–ç  | å…¨éƒ¨åŠ¨æ€è¯»å– | âœ… æ˜“äºä¿®æ”¹ |
| **é‡å¤ä»£ç ** | Web/PDF åˆ†åˆ«åˆ‡åˆ† | å¤ç”¨åŒä¸€é€»è¾‘ | âœ… DRY åŸåˆ™ |
| **è¿‡æ»¤æ—¶æœº** | LLM è°ƒç”¨å | åˆ‡åˆ†æ—¶ï¼ˆæºå¤´ï¼‰ | âœ… èŠ‚çœ API |
| **å¯æ‰©å±•æ€§** | éš¾ä»¥æ·»åŠ æ–°æ¨¡å¼ | ä¿ç•™ `mode` å­—æ®µ | âœ… æ˜“æ‰©å±• |

---

## ğŸ”§ å¦‚ä½•è°ƒæ•´åˆ‡åˆ†å‚æ•°

**ç°åœ¨åªéœ€ä¿®æ”¹ä¸€ä¸ªæ–‡ä»¶**ï¼š`modules/domain_config.py`

### ç¤ºä¾‹ 1: è°ƒæ•´å»ºç­‘æ–‡æ¡£çš„åˆ‡åˆ†å¤§å°

```python
"arch": {
    "chunking": {
        "chunk_size": 1000,  # æ”¹ä¸º 1000 å­—ç¬¦
        "min_length": 300,   # æé«˜æœ€å°é•¿åº¦è¦æ±‚
    },
}
```

### ç¤ºä¾‹ 2: ä¸ºä¼ è¯´æ•…äº‹å¯ç”¨ Markdown æ¨¡å¼ï¼ˆæœªæ¥æ‰©å±•ï¼‰

```python
"legend": {
    "chunking": {
        "mode": "markdown",  # å°†æ¥æ”¯æŒæŒ‰ Markdown æ ‡é¢˜åˆ‡åˆ†
        "chunk_size": 1500,
    },
}
```

**æ— éœ€ä¿®æ”¹ä»»ä½• processor ä»£ç **ï¼Œé…ç½®ç«‹å³ç”Ÿæ•ˆï¼

---

## âœ¨ åç»­æ‰©å±•æ–¹å‘

### 1. æ”¯æŒæ›´å¤š chunking æ¨¡å¼

åœ¨ `pdf_processor._split_text()` ä¸­æ·»åŠ ï¼š

```python
if mode == 'markdown':
    # æŒ‰ Markdown æ ‡é¢˜åˆ‡åˆ†
    from llama_index.core.node_parser import MarkdownNodeParser
    splitter = MarkdownNodeParser()
elif mode == 'semantic':
    # è¯­ä¹‰åˆ‡åˆ†ï¼ˆåŸºäºç›¸ä¼¼åº¦ï¼‰
    from llama_index.core.node_parser import SemanticSplitterNodeParser
    splitter = SemanticSplitterNodeParser(...)
```

### 2. æ™ºèƒ½ chunk å¤§å°è°ƒæ•´

æ ¹æ®æ–‡æ¡£ç±»å‹è‡ªåŠ¨è°ƒæ•´ï¼š

```python
def auto_adjust_chunk_size(text: str, doc_type: str) -> int:
    """æ ¹æ®æ–‡æœ¬é•¿åº¦å’Œç±»å‹åŠ¨æ€è°ƒæ•´ chunk_size"""
    base_size = get_chunking_config(doc_type)['chunk_size']
    if len(text) < 2000:
        return base_size // 2  # çŸ­æ–‡æ¡£ç”¨å°å—
    return base_size
```

### 3. Chunk è´¨é‡è¯„ä¼°

åœ¨æºå¤´è¿‡æ»¤æ—¶å¢åŠ è´¨é‡æ£€æŸ¥ï¼š

```python
def is_valid_chunk(chunk: str, min_length: int) -> bool:
    """è¯„ä¼° chunk è´¨é‡"""
    # é•¿åº¦æ£€æŸ¥
    if len(chunk) < min_length:
        return False
    
    # å†…å®¹è´¨é‡æ£€æŸ¥
    if chunk.count('\n') / len(chunk) > 0.5:  # å¤ªå¤šæ¢è¡Œ
        return False
    
    if len(set(chunk)) < 20:  # å­—ç¬¦ç§ç±»å¤ªå°‘
        return False
    
    return True
```

---

## ğŸ‰ æ€»ç»“

é€šè¿‡è¿™æ¬¡é‡æ„ï¼Œæˆ‘ä»¬å®ç°äº†ï¼š

1. âœ… **é…ç½®é›†ä¸­åŒ–**: æ‰€æœ‰ chunking å‚æ•°é›†ä¸­åœ¨ `domain_config.py`
2. âœ… **ä»£ç å¤ç”¨**: æ‰€æœ‰ processors ä½¿ç”¨åŒä¸€å¥—åˆ‡åˆ†é€»è¾‘
3. âœ… **æ€§èƒ½ä¼˜åŒ–**: æºå¤´è¿‡æ»¤å‡å°‘æ— æ•ˆ LLM è°ƒç”¨
4. âœ… **æ˜“äºç»´æŠ¤**: ä¿®æ”¹é…ç½®æ— éœ€æ”¹ä»£ç 
5. âœ… **ä¿æŒæ‰©å±•æ€§**: ä¿ç•™ `mode` å­—æ®µæ”¯æŒæœªæ¥æ‰©å±•

**ä¸‹ä¸€æ­¥**: å¯ä»¥å¼€å§‹è¿›è¡Œç«¯åˆ°ç«¯æµ‹è¯•ï¼ŒéªŒè¯æ•´ä¸ªæ•°æ®å¤„ç†æµç¨‹ï¼
